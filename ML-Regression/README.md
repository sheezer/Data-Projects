# IBM Machine Learning Professional Certificate
## Supervised Machine Learning: Regression Course

This repository contains the various notebooks completed during the course Supervised Machine Learning: Regression for IBM's Machine Learning Professional Certificate on Coursera.

### 1.1- Transforming Target with Boston Dataset

Transform target variables in a dataset in preparation for regression. Includes how to apply transformations to make target variable more normally distributed for regression and apply inverse transformations to be able to use these in a regression context.

*Tools: Numpy, Pandas, Scikit-learn, Matplotlib*

### 1.2- Linear Regression with Car Price Dataset

Applies linear regression to the car price dataset. This involves selecting significant features based on a visual analysis, checking assumptions for a linear regression model, applying linear regression model to make predictions of car prices based on different feature combinations and applying pipelines for data transformation. 

*Tools: Numpy, Pandas, Scikit-learn, Seaborn, Scipy, Matplotlib, Itertools*

### 2.1- Regression Train Test Split with Ames Housing Dataset

Applies linear regression to the Ames Housing dataset. This involves carrying out all the necessary steps to prepare the data for the task including EDA, one-hot encoding categorical data and label encoding target data, train test split of data and data scaling along with Linear Regression.

*Tools: Numpy, Pandas, Scikit-learn, Seaborn, Matplotlib*

### 2.2- Polynomial Regression with Cars Dataset

Applies polynomial regression to data by first performing EDA, train test split, Linear Regression, Polynomial transformation of data and Polynomial regression afterwards. Furrher deals with model overfitting and model underfitting as well as hyperparameter grid selection.

*Tools: Numpy, Pandas, Scikit-learn, Seaborn, Scipy, Matplotlib, Itertools*

### 3.1- Cross Validation with Boston Housing Dataset

Discusses pickling, hyperparameter tuning and regularization. Introduces Ridge and Lasso Regression.

*Tools: Numpy, Pickle, Pandas, Scikit-learn, Matplotlib*

### 3.2- Cross Validation with Cars Dataset

Discusses train test split, cross validation with k-folds and cross validation scores to select hyperparameters.

*Tools: Numpy, Seaborn, Pandas, Scikit-learn, Matplotlib*

### 4- Regularization with Ames Housing Dataset

Applies Polynomial Regression, Ridge Regression and Lasso Regression to data. Involves log transforming and scaling data. Also looks at Stochastic Gradient Descent as regressor.

*Tools: Numpy, Pandas, Scikit-learn, Matplotlib, Seaborn*

### 5.1- Regularization with Boston Housing Dataset

Implements data standardization and variants of regularized regression. Combines data standardization with train-test splitting procedure. Avoids overfitting.

*Tools: Numpy, Pandas, Scikit-learn, Matplotlib*

### 5.2- Regularization Techniques with Cars Dataset

Introduces ElasticNet Regression. Discusses the advantages and disadvantages of various regularization techniques. Performs grid search on validated data to find optimal hyperparameters. Also applies Principal Component Analysis to data.

*Tools: Numpy, Pandas, Scikit-learn, Matplotlib, Seaborn*

### Regression Final Project Notebook

The Final Project makes use of a Life Expectancy dataset to understand the impact of different features on life expectancy between different countries. The dataset and related details can be found at the link: [Dataset Link](https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who)

The project makes use of EDA, data cleaning and feature engineering. It applies Polynomial Regression, Linear Regression, Lasso Regression, Ridge Regression and ElasticNet Regression on the dataset. It also makes use of data standardization and PCA on the data. Includes a bonus where some advanced regression techniques for specific use cases were attempted. 

*Tools: Numpy, Pandas, Scikit-learn, Matplotlib, Seaborn*

### Regression Final Project Report

A report about the Final Project undertaken on the Life Expectancy dataset. Discusses the results from different regression techniques and overall findings from the project.
